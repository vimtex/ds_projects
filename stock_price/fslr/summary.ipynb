{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I compared several models to predict the next-day stock price (adj_close):\n",
    "* the naive persistence model, which directly use today's price for the future\n",
    "* ARIMA/SARIMA (sigle variable, using the historical adj_close data)\n",
    "* Linear Regression (use the date as the feature)\n",
    "* LSTM (using history data)\n",
    " * commonly used MinMaxScaler preprocessing\n",
    " * Mixed StandardScaler preprocessing\n",
    "* XGBoost\n",
    " * Mixed StandardScaler preprocessing, using other historical data as features\n",
    " * Mixed StandardScaler preprocessing, further using date-related features\n",
    " \n",
    "The most important conclusion is that: the naive persistence model is probably the best, and all the other models either fall back to it with specific optimal parameters (like in the ARIMA model, p=0, q=0, and d=1), or very close to it (like in the XGBoost models, the lag 1 adj_close feature having the highest feature importance).\n",
    "\n",
    "The most impressive thing is the usage of the mixed scaler preprocessiong, which greatly improve the LSTM and XGBoost models. I call it a mixed one since the training set are treated as normal, as a whole, but the test set is not directly preprocessed using the scaler, but scaled with the local mean and std (calculated within a nearby window). This allows to use the train set as a whole for training the model, and also anchor the prediction to the local mean and std.\n",
    "\n",
    "This project is inspired by the [blog](https://cloud.tencent.com/developer/article/1395756), and I actually used some of their source codes after fully understanding all of them. I further made two XGBoost models to recursively predict the stock price in the future 21 days (one month). But due to facts discussed above, the prediction is quite bad (for 21 days or similar long intervals the model may be marginally better than the naive persistence one, but for short intervals the models may be even worse).  \n",
    "\n",
    "In short, using historical data only to predict stock price may be not a good idea (good for post-analysis apparently), extra features are needed, for examles:\n",
    "* news, twitters \n",
    "* related policy\n",
    "* related technical breakthrough\n",
    "* insider information like the meeting of the managers, etc. \n",
    "Al"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
